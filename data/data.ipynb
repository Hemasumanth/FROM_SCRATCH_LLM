{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d1305cf-12d5-46fe-a2c9-36fb71c5b3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.5.1\n",
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a769e87-470a-48b9-8bdb-12841b416198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737dd5b0-9dbb-4a97-9ae4-3482c8c04be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '--', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--', 'so', ' ', 'it', ' ', 'was', ' ', 'no', ' ']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item for item in preprocessed if item]\n",
    "print(preprocessed[:38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35db7b5e-510b-4c45-995f-f5ad64a8e19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 8405\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of tokens:\", len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fdf0533-5ab6-42a5-83fa-a3b045de6396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77d00d96-881f-4691-bb03-84fec2a75a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "963e5b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '--': 8, '.': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'Ah': 14, 'Among': 15, 'And': 16, 'Are': 17, 'Arrt': 18, 'As': 19, 'At': 20, 'Be': 21, 'Begin': 22, 'Burlington': 23, 'But': 24, 'By': 25, 'Carlo': 26, 'Chicago': 27, 'Claude': 28, 'Come': 29, 'Croft': 30, 'Destroyed': 31, 'Devonshire': 32, 'Don': 33, 'Dubarry': 34, 'Emperors': 35, 'Florence': 36, 'For': 37, 'Gallery': 38, 'Gideon': 39, 'Gisburn': 40, 'Gisburns': 41, 'Grafton': 42, 'Greek': 43, 'Grindle': 44, 'Grindles': 45, 'HAD': 46, 'Had': 47, 'Hang': 48, 'Has': 49, 'He': 50, 'Her': 51, 'Hermia': 52, 'His': 53, 'How': 54, 'I': 55, 'If': 56, 'In': 57, 'It': 58, 'Jack': 59, 'Jove': 60, 'Just': 61, 'Lord': 62, 'Made': 63, 'Miss': 64, 'Money': 65, 'Monte': 66, 'Moon-dancers': 67, 'Mr': 68, 'Mrs': 69, 'My': 70, 'Never': 71, 'No': 72, 'Now': 73, 'Nutley': 74, 'Of': 75, 'Oh': 76, 'On': 77, 'Once': 78, 'Only': 79, 'Or': 80, 'Perhaps': 81, 'Poor': 82, 'Professional': 83, 'Renaissance': 84, 'Rickham': 85, 'Riviera': 86, 'Rome': 87, 'Russian': 88, 'Sevres': 89, 'She': 90, 'Stroud': 91, 'Strouds': 92, 'Suddenly': 93, 'That': 94, 'The': 95, 'Then': 96, 'There': 97, 'They': 98, 'This': 99, 'Those': 100, 'Though': 101, 'Thwing': 102, 'Thwings': 103, 'To': 104, 'Usually': 105, 'Venetian': 106, 'Victor': 107, 'Was': 108, 'We': 109, 'Well': 110, 'What': 111, 'When': 112, 'Why': 113, 'Yes': 114, 'You': 115, '_': 116, 'a': 117, 'abdication': 118, 'able': 119, 'about': 120, 'above': 121, 'abruptly': 122, 'absolute': 123, 'absorbed': 124, 'absurdity': 125, 'academic': 126, 'accuse': 127, 'accustomed': 128, 'across': 129, 'activity': 130, 'add': 131, 'added': 132, 'admirers': 133, 'adopted': 134, 'adulation': 135, 'advance': 136, 'aesthetic': 137, 'affect': 138, 'afraid': 139, 'after': 140, 'afterward': 141, 'again': 142, 'ago': 143, 'ah': 144, 'air': 145, 'alive': 146, 'all': 147, 'almost': 148, 'alone': 149, 'along': 150, 'always': 151, 'am': 152, 'amazement': 153, 'amid': 154, 'among': 155, 'amplest': 156, 'amusing': 157, 'an': 158, 'and': 159, 'another': 160, 'answer': 161, 'answered': 162, 'any': 163, 'anything': 164, 'anywhere': 165, 'apparent': 166, 'apparently': 167, 'appearance': 168, 'appeared': 169, 'appointed': 170, 'are': 171, 'arm': 172, 'arm-chair': 173, 'arm-chairs': 174, 'arms': 175, 'art': 176, 'articles': 177, 'artist': 178, 'as': 179, 'aside': 180, 'asked': 181, 'at': 182, 'atmosphere': 183, 'atom': 184, 'attack': 185, 'attention': 186, 'attitude': 187, 'audacities': 188, 'away': 189, 'awful': 190, 'axioms': 191, 'azaleas': 192, 'back': 193, 'background': 194, 'balance': 195, 'balancing': 196, 'balustraded': 197, 'basking': 198, 'bath-rooms': 199, 'be': 200, 'beaming': 201, 'bean-stalk': 202, 'bear': 203, 'beard': 204, 'beauty': 205, 'became': 206, 'because': 207, 'becoming': 208, 'bed': 209, 'been': 210, 'before': 211, 'began': 212, 'begun': 213, 'behind': 214, 'being': 215, 'believed': 216, 'beneath': 217, 'bespoke': 218, 'better': 219, 'between': 220, 'big': 221, 'bits': 222, 'bitterness': 223, 'blocked': 224, 'born': 225, 'borne': 226, 'boudoir': 227, 'bravura': 228, 'break': 229, 'breaking': 230, 'breathing': 231, 'bric-a-brac': 232, 'briefly': 233, 'brings': 234, 'bronzes': 235, 'brought': 236, 'brown': 237, 'brush': 238, 'bull': 239, 'business': 240, 'but': 241, 'buying': 242, 'by': 243, 'called': 244, 'came': 245, 'can': 246, 'canvas': 247, 'canvases': 248, 'cards': 249, 'care': 250, 'career': 251, 'caught': 252, 'central': 253, 'chair': 254, 'chap': 255, 'characteristic': 256, 'charming': 257, 'cheap': 258, 'check': 259, 'cheeks': 260, 'chest': 261, 'chimney-piece': 262, 'chucked': 263, 'cigar': 264, 'cigarette': 265, 'cigars': 266, 'circulation': 267, 'circumstance': 268, 'circus-clown': 269, 'claimed': 270, 'clasping': 271, 'clear': 272, 'cleverer': 273, 'close': 274, 'clue': 275, 'coat': 276, 'collapsed': 277, 'colour': 278, 'come': 279, 'comfortable': 280, 'coming': 281, 'companion': 282, 'compared': 283, 'complex': 284, 'confident': 285, 'congesting': 286, 'conjugal': 287, 'constraint': 288, 'consummate': 289, 'contended': 290, 'continued': 291, 'corner': 292, 'corrected': 293, 'could': 294, 'couldn': 295, 'count': 296, 'countenance': 297, 'couple': 298, 'course': 299, 'covered': 300, 'craft': 301, 'cried': 302, 'crossed': 303, 'crowned': 304, 'crumbled': 305, 'cry': 306, 'cured': 307, 'curiosity': 308, 'curious': 309, 'current': 310, 'curtains': 311, 'd': 312, 'dabble': 313, 'damask': 314, 'dark': 315, 'dashed': 316, 'day': 317, 'days': 318, 'dead': 319, 'deadening': 320, 'dear': 321, 'deep': 322, 'deerhound': 323, 'degree': 324, 'delicate': 325, 'demand': 326, 'denied': 327, 'deploring': 328, 'deprecating': 329, 'deprecatingly': 330, 'desire': 331, 'destroyed': 332, 'destruction': 333, 'desultory': 334, 'detail': 335, 'diagnosis': 336, 'did': 337, 'didn': 338, 'died': 339, 'dim': 340, 'dimmest': 341, 'dingy': 342, 'dining-room': 343, 'disarming': 344, 'discovery': 345, 'discrimination': 346, 'discussion': 347, 'disdain': 348, 'disdained': 349, 'disease': 350, 'disguised': 351, 'display': 352, 'dissatisfied': 353, 'distinguished': 354, 'distract': 355, 'divert': 356, 'do': 357, 'doesn': 358, 'doing': 359, 'domestic': 360, 'don': 361, 'done': 362, 'donkey': 363, 'down': 364, 'dozen': 365, 'dragged': 366, 'drawing-room': 367, 'drawing-rooms': 368, 'drawn': 369, 'dress-closets': 370, 'drew': 371, 'dropped': 372, 'each': 373, 'earth': 374, 'ease': 375, 'easel': 376, 'easy': 377, 'echoed': 378, 'economy': 379, 'effect': 380, 'effects': 381, 'efforts': 382, 'egregious': 383, 'eighteenth-century': 384, 'elbow': 385, 'elegant': 386, 'else': 387, 'embarrassed': 388, 'enabled': 389, 'end': 390, 'endless': 391, 'enjoy': 392, 'enlightenment': 393, 'enough': 394, 'ensuing': 395, 'equally': 396, 'equanimity': 397, 'escape': 398, 'established': 399, 'etching': 400, 'even': 401, 'event': 402, 'ever': 403, 'everlasting': 404, 'every': 405, 'exasperated': 406, 'except': 407, 'excuse': 408, 'excusing': 409, 'existed': 410, 'expected': 411, 'exquisite': 412, 'exquisitely': 413, 'extenuation': 414, 'exterminating': 415, 'extracting': 416, 'eye': 417, 'eyebrows': 418, 'eyes': 419, 'face': 420, 'faces': 421, 'fact': 422, 'faded': 423, 'failed': 424, 'failure': 425, 'fair': 426, 'faith': 427, 'false': 428, 'familiar': 429, 'famille-verte': 430, 'fancy': 431, 'fashionable': 432, 'fate': 433, 'feather': 434, 'feet': 435, 'fell': 436, 'fellow': 437, 'felt': 438, 'few': 439, 'fewer': 440, 'finality': 441, 'find': 442, 'fingers': 443, 'first': 444, 'fit': 445, 'fitting': 446, 'five': 447, 'flash': 448, 'flashed': 449, 'florid': 450, 'flowers': 451, 'fluently': 452, 'flung': 453, 'follow': 454, 'followed': 455, 'fond': 456, 'footstep': 457, 'for': 458, 'forced': 459, 'forcing': 460, 'forehead': 461, 'foreign': 462, 'foreseen': 463, 'forgive': 464, 'forgotten': 465, 'form': 466, 'formed': 467, 'forming': 468, 'forward': 469, 'fostered': 470, 'found': 471, 'foundations': 472, 'fragment': 473, 'fragments': 474, 'frame': 475, 'frames': 476, 'frequently': 477, 'friend': 478, 'from': 479, 'full': 480, 'fullest': 481, 'furiously': 482, 'furrowed': 483, 'garlanded': 484, 'garlands': 485, 'gave': 486, 'genial': 487, 'genius': 488, 'gesture': 489, 'get': 490, 'getting': 491, 'give': 492, 'given': 493, 'glad': 494, 'glanced': 495, 'glimpse': 496, 'gloried': 497, 'glory': 498, 'go': 499, 'going': 500, 'gone': 501, 'good': 502, 'good-breeding': 503, 'good-humoured': 504, 'got': 505, 'grace': 506, 'gradually': 507, 'gray': 508, 'grayish': 509, 'great': 510, 'greatest': 511, 'greatness': 512, 'grew': 513, 'groping': 514, 'growing': 515, 'had': 516, 'hadn': 517, 'hair': 518, 'half': 519, 'half-light': 520, 'half-mechanically': 521, 'hall': 522, 'hand': 523, 'hands': 524, 'handsome': 525, 'hanging': 526, 'happen': 527, 'happened': 528, 'hard': 529, 'hardly': 530, 'has': 531, 'have': 532, 'haven': 533, 'having': 534, 'he': 535, 'head': 536, 'hear': 537, 'heard': 538, 'heart': 539, 'height': 540, 'her': 541, 'here': 542, 'hermit': 543, 'herself': 544, 'hesitations': 545, 'hide': 546, 'high': 547, 'him': 548, 'himself': 549, 'hint': 550, 'his': 551, 'history': 552, 'holding': 553, 'home': 554, 'honour': 555, 'hooded': 556, 'hostess': 557, 'hot-house': 558, 'hour': 559, 'hours': 560, 'house': 561, 'how': 562, 'hung': 563, 'husband': 564, 'idea': 565, 'idle': 566, 'idling': 567, 'if': 568, 'immediately': 569, 'in': 570, 'incense': 571, 'indifferent': 572, 'inevitable': 573, 'inevitably': 574, 'inflexible': 575, 'insensible': 576, 'insignificant': 577, 'instinctively': 578, 'instructive': 579, 'interesting': 580, 'into': 581, 'ironic': 582, 'irony': 583, 'irrelevance': 584, 'irrevocable': 585, 'is': 586, 'it': 587, 'its': 588, 'itself': 589, 'jardiniere': 590, 'jealousy': 591, 'just': 592, 'keep': 593, 'kept': 594, 'kind': 595, 'knees': 596, 'knew': 597, 'know': 598, 'known': 599, 'laid': 600, 'lair': 601, 'landing': 602, 'language': 603, 'last': 604, 'late': 605, 'later': 606, 'latter': 607, 'laugh': 608, 'laughed': 609, 'lay': 610, 'leading': 611, 'lean': 612, 'learned': 613, 'least': 614, 'leathery': 615, 'leave': 616, 'led': 617, 'left': 618, 'leisure': 619, 'lends': 620, 'lent': 621, 'let': 622, 'lies': 623, 'life': 624, 'life-likeness': 625, 'lift': 626, 'lifted': 627, 'light': 628, 'lightly': 629, 'like': 630, 'liked': 631, 'line': 632, 'lines': 633, 'lingered': 634, 'lips': 635, 'lit': 636, 'little': 637, 'live': 638, 'll': 639, 'loathing': 640, 'long': 641, 'longed': 642, 'longer': 643, 'look': 644, 'looked': 645, 'looking': 646, 'lose': 647, 'loss': 648, 'lounging': 649, 'lovely': 650, 'lucky': 651, 'lump': 652, 'luncheon-table': 653, 'luxury': 654, 'lying': 655, 'made': 656, 'make': 657, 'man': 658, 'manage': 659, 'managed': 660, 'mantel-piece': 661, 'marble': 662, 'married': 663, 'may': 664, 'me': 665, 'meant': 666, 'mediocrity': 667, 'medium': 668, 'mentioned': 669, 'mere': 670, 'merely': 671, 'met': 672, 'might': 673, 'mighty': 674, 'millionaire': 675, 'mine': 676, 'minute': 677, 'minutes': 678, 'mirrors': 679, 'modest': 680, 'modesty': 681, 'moment': 682, 'money': 683, 'monumental': 684, 'mood': 685, 'morbidly': 686, 'more': 687, 'most': 688, 'mourn': 689, 'mourned': 690, 'moustache': 691, 'moved': 692, 'much': 693, 'muddling': 694, 'multiplied': 695, 'murmur': 696, 'muscles': 697, 'must': 698, 'my': 699, 'myself': 700, 'mysterious': 701, 'naive': 702, 'near': 703, 'nearly': 704, 'negatived': 705, 'nervous': 706, 'nervousness': 707, 'neutral': 708, 'never': 709, 'next': 710, 'no': 711, 'none': 712, 'not': 713, 'note': 714, 'nothing': 715, 'now': 716, 'nymphs': 717, 'oak': 718, 'obituary': 719, 'object': 720, 'objects': 721, 'occurred': 722, 'oddly': 723, 'of': 724, 'off': 725, 'often': 726, 'oh': 727, 'old': 728, 'on': 729, 'once': 730, 'one': 731, 'ones': 732, 'only': 733, 'onto': 734, 'open': 735, 'or': 736, 'other': 737, 'our': 738, 'ourselves': 739, 'out': 740, 'outline': 741, 'oval': 742, 'over': 743, 'own': 744, 'packed': 745, 'paid': 746, 'paint': 747, 'painted': 748, 'painter': 749, 'painting': 750, 'pale': 751, 'paled': 752, 'palm-trees': 753, 'panel': 754, 'panelling': 755, 'pardonable': 756, 'pardoned': 757, 'part': 758, 'passages': 759, 'passing': 760, 'past': 761, 'pastels': 762, 'pathos': 763, 'patient': 764, 'people': 765, 'perceptible': 766, 'perfect': 767, 'persistence': 768, 'persuasively': 769, 'phrase': 770, 'picture': 771, 'pictures': 772, 'pines': 773, 'pink': 774, 'place': 775, 'placed': 776, 'plain': 777, 'platitudes': 778, 'pleased': 779, 'pockets': 780, 'point': 781, 'poised': 782, 'poor': 783, 'portrait': 784, 'posing': 785, 'possessed': 786, 'poverty': 787, 'predicted': 788, 'preliminary': 789, 'presenting': 790, 'prestidigitation': 791, 'pretty': 792, 'previous': 793, 'price': 794, 'pride': 795, 'princely': 796, 'prism': 797, 'problem': 798, 'proclaiming': 799, 'prodigious': 800, 'profusion': 801, 'protest': 802, 'prove': 803, 'public': 804, 'purblind': 805, 'purely': 806, 'pushed': 807, 'put': 808, 'qualities': 809, 'quality': 810, 'queerly': 811, 'question': 812, 'quickly': 813, 'quietly': 814, 'quite': 815, 'quote': 816, 'rain': 817, 'raised': 818, 'random': 819, 'rather': 820, 're': 821, 'real': 822, 'really': 823, 'reared': 824, 'reason': 825, 'reassurance': 826, 'recovering': 827, 'recreated': 828, 'reflected': 829, 'reflection': 830, 'regrets': 831, 'relatively': 832, 'remained': 833, 'remember': 834, 'reminded': 835, 'repeating': 836, 'represented': 837, 'reproduction': 838, 'resented': 839, 'resolve': 840, 'resources': 841, 'rest': 842, 'rich': 843, 'ridiculous': 844, 'robbed': 845, 'romantic': 846, 'room': 847, 'rose': 848, 'rs': 849, 'rule': 850, 'run': 851, 's': 852, 'said': 853, 'same': 854, 'satisfaction': 855, 'savour': 856, 'saw': 857, 'say': 858, 'saying': 859, 'says': 860, 'scorn': 861, 'scornful': 862, 'secret': 863, 'see': 864, 'seemed': 865, 'seen': 866, 'self-confident': 867, 'send': 868, 'sensation': 869, 'sensitive': 870, 'sent': 871, 'serious': 872, 'set': 873, 'sex': 874, 'shade': 875, 'shaking': 876, 'shall': 877, 'she': 878, 'shirked': 879, 'short': 880, 'should': 881, 'shoulder': 882, 'shoulders': 883, 'show': 884, 'showed': 885, 'showy': 886, 'shrug': 887, 'shrugged': 888, 'sight': 889, 'sign': 890, 'silent': 891, 'silver': 892, 'similar': 893, 'simpleton': 894, 'simplifications': 895, 'simply': 896, 'since': 897, 'single': 898, 'sitter': 899, 'sitters': 900, 'sketch': 901, 'skill': 902, 'slight': 903, 'slightly': 904, 'slowly': 905, 'small': 906, 'smile': 907, 'smiling': 908, 'sneer': 909, 'so': 910, 'solace': 911, 'some': 912, 'somebody': 913, 'something': 914, 'spacious': 915, 'spaniel': 916, 'speaking-tubes': 917, 'speculations': 918, 'spite': 919, 'splash': 920, 'square': 921, 'stairs': 922, 'stammer': 923, 'stand': 924, 'standing': 925, 'started': 926, 'stay': 927, 'still': 928, 'stocked': 929, 'stood': 930, 'stopped': 931, 'stopping': 932, 'straddling': 933, 'straight': 934, 'strain': 935, 'straining': 936, 'strange': 937, 'straw': 938, 'stream': 939, 'stroke': 940, 'strokes': 941, 'strolled': 942, 'strongest': 943, 'strongly': 944, 'struck': 945, 'studio': 946, 'stuff': 947, 'subject': 948, 'substantial': 949, 'suburban': 950, 'such': 951, 'suddenly': 952, 'suffered': 953, 'sugar': 954, 'suggested': 955, 'sunburn': 956, 'sunburnt': 957, 'sunlit': 958, 'superb': 959, 'sure': 960, 'surest': 961, 'surface': 962, 'surprise': 963, 'surprised': 964, 'surrounded': 965, 'suspected': 966, 'sweetly': 967, 'sweetness': 968, 'swelling': 969, 'swept': 970, 'swum': 971, 't': 972, 'table': 973, 'take': 974, 'taken': 975, 'talking': 976, 'tea': 977, 'tears': 978, 'technicalities': 979, 'technique': 980, 'tell': 981, 'tells': 982, 'tempting': 983, 'terra-cotta': 984, 'terrace': 985, 'terraces': 986, 'terribly': 987, 'than': 988, 'that': 989, 'the': 990, 'their': 991, 'them': 992, 'then': 993, 'there': 994, 'therefore': 995, 'they': 996, 'thin': 997, 'thing': 998, 'things': 999, 'think': 1000, 'this': 1001, 'thither': 1002, 'those': 1003, 'though': 1004, 'thought': 1005, 'three': 1006, 'threshold': 1007, 'threw': 1008, 'through': 1009, 'throwing': 1010, 'tie': 1011, 'till': 1012, 'time': 1013, 'timorously': 1014, 'tinge': 1015, 'tips': 1016, 'tired': 1017, 'to': 1018, 'told': 1019, 'tone': 1020, 'tones': 1021, 'too': 1022, 'took': 1023, 'tottering': 1024, 'touched': 1025, 'toward': 1026, 'trace': 1027, 'trade': 1028, 'transmute': 1029, 'traps': 1030, 'travelled': 1031, 'tribute': 1032, 'tributes': 1033, 'tricks': 1034, 'tried': 1035, 'trouser-presses': 1036, 'true': 1037, 'truth': 1038, 'turned': 1039, 'twenty': 1040, 'twenty-four': 1041, 'twice': 1042, 'twirling': 1043, 'unaccountable': 1044, 'uncertain': 1045, 'under': 1046, 'underlay': 1047, 'underneath': 1048, 'understand': 1049, 'unexpected': 1050, 'untouched': 1051, 'unusual': 1052, 'up': 1053, 'up-stream': 1054, 'upon': 1055, 'upset': 1056, 'upstairs': 1057, 'us': 1058, 'used': 1059, 'usual': 1060, 'value': 1061, 'varnishing': 1062, 'vases': 1063, 've': 1064, 'veins': 1065, 'velveteen': 1066, 'very': 1067, 'villa': 1068, 'vindicated': 1069, 'virtuosity': 1070, 'vista': 1071, 'vocation': 1072, 'voice': 1073, 'wall': 1074, 'wander': 1075, 'want': 1076, 'wanted': 1077, 'wants': 1078, 'was': 1079, 'wasn': 1080, 'watched': 1081, 'watching': 1082, 'water-colour': 1083, 'waves': 1084, 'way': 1085, 'weekly': 1086, 'weeks': 1087, 'welcome': 1088, 'went': 1089, 'were': 1090, 'what': 1091, 'when': 1092, 'whenever': 1093, 'where': 1094, 'which': 1095, 'while': 1096, 'white': 1097, 'white-panelled': 1098, 'who': 1099, 'whole': 1100, 'whom': 1101, 'why': 1102, 'wide': 1103, 'widow': 1104, 'wife': 1105, 'wild': 1106, 'wincing': 1107, 'window-curtains': 1108, 'wish': 1109, 'with': 1110, 'without': 1111, 'wits': 1112, 'woman': 1113, 'women': 1114, 'won': 1115, 'wonder': 1116, 'wondered': 1117, 'word': 1118, 'work': 1119, 'working': 1120, 'worth': 1121, 'would': 1122, 'wouldn': 1123, 'year': 1124, 'years': 1125, 'yellow': 1126, 'yet': 1127, 'you': 1128, 'younger': 1129, 'your': 1130, 'yourself': 1131}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1c5de4a-aa4e-4aec-b532-10bb364039d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n', 0)\n",
      "(' ', 1)\n",
      "('!', 2)\n",
      "('\"', 3)\n",
      "(\"'\", 4)\n",
      "('(', 5)\n",
      "(')', 6)\n",
      "(',', 7)\n",
      "('--', 8)\n",
      "('.', 9)\n",
      "(':', 10)\n",
      "(';', 11)\n",
      "('?', 12)\n",
      "('A', 13)\n",
      "('Ah', 14)\n",
      "('Among', 15)\n",
      "('And', 16)\n",
      "('Are', 17)\n",
      "('Arrt', 18)\n",
      "('As', 19)\n",
      "('At', 20)\n",
      "('Be', 21)\n",
      "('Begin', 22)\n",
      "('Burlington', 23)\n",
      "('But', 24)\n",
      "('By', 25)\n",
      "('Carlo', 26)\n",
      "('Chicago', 27)\n",
      "('Claude', 28)\n",
      "('Come', 29)\n",
      "('Croft', 30)\n",
      "('Destroyed', 31)\n",
      "('Devonshire', 32)\n",
      "('Don', 33)\n",
      "('Dubarry', 34)\n",
      "('Emperors', 35)\n",
      "('Florence', 36)\n",
      "('For', 37)\n",
      "('Gallery', 38)\n",
      "('Gideon', 39)\n",
      "('Gisburn', 40)\n",
      "('Gisburns', 41)\n",
      "('Grafton', 42)\n",
      "('Greek', 43)\n",
      "('Grindle', 44)\n",
      "('Grindles', 45)\n",
      "('HAD', 46)\n",
      "('Had', 47)\n",
      "('Hang', 48)\n",
      "('Has', 49)\n",
      "('He', 50)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i >= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e569647-2589-4c9d-9a5c-aef1c88a0a9a",
   "metadata": {},
   "source": [
    "- Let's now put it all together into a tokenizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531bf46-7c25-4ef8-bff8-0d27518676d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "        \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "647364ec-7995-4654-9b4a-7607ccf5f1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 58, 4, 852, 990, 604, 535, 748, 7, 1128, 598, 7, 3, 69, 9, 40, 853, 1110, 756, 795, 9]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    "           Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d8c8fb-432d-4a49-b332-99f23b233746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54f6aa8b-9827-412e-9035-e827296ab0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede1d41f-934b-4bf4-8184-54394a257a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48967a77-7d17-42bf-9e92-fc619d63a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ad3312f-a5f7-4efc-9d7d-8ea09d7b5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ff2cd85-7cfb-4325-b390-219938589428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d26a48bb-f82e-41a8-a955-a1c9cf9d50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0beb27ee-1156-457c-839e-eebb48d94d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[33901, 86, 343, 86, 220, 959]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Akwirw ier\", allowed_special={\"<|endoftext|>\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55f51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "from supplementary import create_dataloader_v1\n",
    "\n",
    "\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
